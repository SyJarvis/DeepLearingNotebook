# 过拟合、欠拟合及其解决方案(笔记)

模型选择



**训练误差(training error)**：指模型在训练数据集上表现出的误差。

**泛化误差(generalization)**：指模型在任意一个测试数据样本上表现出的误差的期望值，并常常通过测试数据集上的误差来近似。

**机器学习模型应关注泛化误差**

**验证数据集**：在训练数据集和测试数据集以外的数据集合

**K折交叉验证**：产生背景：由于验证数据集不参与模型训练，当训练数据不够用时，预留大量的验证数据显得太奢侈。原理：把原始训练数据集分割成K个不重合的子数据集，然后我们做K次模型验证和训练。每一次都会使用一个子数据集验证模型，并使用其他K-1个子数据集来训练模型。**最后**，对K次训练误差和验证误差分别求平均。

**欠拟合**：模型无法得到较低的训练误差，（预测值与真实值拟合程度太低）

**过拟合**：模型的训练误差远小于它在测试数据集上的误差，（预测值与真实值拟合程度太高）



**模型复杂度**：。。。



**训练数据集大小**：影响欠拟合和过拟合的另一个重要因素是训练数据集的大小。一般来说，如果训练数据集中样本数过少，特别是比模型参数数量（按元素计）更少时，过拟合更容易发生。此外，泛化误差不会随训练数据集里样本数量增加而增大。因此，在计算资源允许的范围之内，我们通常希望训练数据集大一些，特别是在模型复杂度较高时，例如层数较多的深度学习模型。

